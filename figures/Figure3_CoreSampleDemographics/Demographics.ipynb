{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import matplotlib\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..','..','data')\n",
    "# census\n",
    "census = pd.read_csv(os.path.join(data_dir, 'ACS_DemHousingEst2018ACS_2018_censusEstimate.csv'))\n",
    "# core sample\n",
    "core_data =  pd.read_csv(os.path.join(data_dir, 'core_dem.csv'))\n",
    "# excluded sample\n",
    "excluded_data =  pd.read_csv(os.path.join(data_dir, 'excluded_dem.csv'))\n",
    "# low completion sample\n",
    "lowCompl_data =  pd.read_csv(os.path.join(data_dir, 'lowCompl_dem.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic sample summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poli_affil(survey_data, col_name_extension = ''):\n",
    "    \"\"\"\n",
    "    Gathers party affiliation and political leaning, and recodes semantically, \n",
    "    e.g. 1.0 -> Republican, 2.0 -> Democrat, etc\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing demographic raw data\n",
    "        col_name_extension (string): output column name extension  (default = none)\n",
    "\n",
    "    Returns:\n",
    "        party (pd.DataFrame): party affiliation distribution in survey_data\n",
    "        polit_lean (pd.DataFrame): political leaning distribution in survey_data\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract: DemM6-> party affiliation; DemM7-> political leaning\n",
    "    survey = survey_data[['DemM6', 'DemM7']].astype(str)\n",
    "    \n",
    "    # column name extension \n",
    "    party_col_name = 'party'+ col_name_extension\n",
    "    lean_col_name = 'polit. lean.'+ col_name_extension \n",
    "    \n",
    "    # semantic recoding \n",
    "    survey = survey.rename(columns = {'DemM6': party_col_name,'DemM7': lean_col_name})\n",
    "    party_names={'1.0':'Republican', '2.0':'Democrat', '3.0':'Independant', '4.0':'Other'}\n",
    "    lean_names = {'1.0':'strongly liberal', '2.0':'moderately liberal', '3.0':'slightly liberal',\n",
    "                 '4.0':'neutral', '5.0':'slightly conservative', '6.0':'moderately conservative', '7.0':'strongly conservative'}\n",
    "    survey = survey.replace({party_col_name: party_names}) \n",
    "    survey = survey.replace({lean_col_name: lean_names}) \n",
    "    \n",
    "    # party affiliation distribution in survey_data\n",
    "    party = survey[party_col_name].value_counts(normalize=True) * 100\n",
    "    party = party.to_frame()\n",
    "    party[party_col_name] = party[party_col_name].round(decimals=2)\n",
    "    # political leaning distribution in survey_data\n",
    "    polit_lean = survey[lean_col_name].value_counts(normalize=True) * 100\n",
    "    polit_lean = polit_lean.to_frame()\n",
    "    polit_lean[lean_col_name] = polit_lean[lean_col_name].round(decimals=2)\n",
    "    \n",
    "    return party, polit_lean\n",
    "\n",
    "\n",
    "\n",
    "def employment_income(survey_data, col_name_extension):\n",
    "    \"\"\"\n",
    "    Gathers employment status  and weekly income, and recodes semantically, \n",
    "    e.g. 1.0 -> employed, 2.0 -> unemployed, etc.\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing demographic raw data\n",
    "        col_name_extension (string): output column name extension  (default = none)\n",
    "\n",
    "    Returns:\n",
    "        employment (pd.DataFrame): employment status distribution in survey_data\n",
    "        income (pd.DataFrame): income bracket distribution in survey_data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract: DemW10_R1-> employment status; DemW18_R1-> income bracket\n",
    "    survey = survey_data[['DemW10_R1', 'DemW18_R1']].astype(str)\n",
    "    \n",
    "    # column name extension \n",
    "    employment_name = 'employment'+ col_name_extension\n",
    "    income_name = 'weekIncome'+col_name_extension \n",
    "    \n",
    "    # semantic recoding \n",
    "    survey = survey.rename(columns = {'DemW10_R1': employment_name,'DemW18_R1': income_name})\n",
    "    employment_names={'1.0':'employed', '2.0':'unemployed', '3.0':'retired'}\n",
    "    income_names = {'1.0': 'Less than $249', '2.0' : '$250 - $499', '3.0': '$500 - $999', '4.0':'$1000 -$1499', '5.0':'$1500 - $2999', '6.0':'more than $3000', '7.0' :'Dont know'}\n",
    "    survey = survey.replace({employment_name: employment_names}) \n",
    "    survey = survey.replace({income_name: income_names}) \n",
    "    \n",
    "    # employment status distribution in survey_data\n",
    "    employment = survey[employment_name].value_counts(normalize=True) * 100\n",
    "    employment = employment.to_frame()\n",
    "    employment[employment_name] = employment[employment_name].round(decimals=2)\n",
    "    # income bracket distribution in survey_data\n",
    "    income = survey[income_name].value_counts(normalize=True) * 100\n",
    "    income = income.to_frame()\n",
    "    income[income_name] = income[income_name].round(decimals=2)\n",
    "    \n",
    "    return employment, income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_data(survey_data, census_data):\n",
    "    \"\"\"\n",
    "    Gathers state of residence distribution in census and survey data\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing sample demographic raw data\n",
    "        census_data (string): dataframe containing census demographics\n",
    "        \n",
    "    Returns:\n",
    "        combined (pd.DataFrame): combined state information (normalised)\n",
    "    \"\"\"\n",
    "        \n",
    "    # state dictionary\n",
    "    state_dict = {'1.0': 'Alabama', '2.0': 'Alaska', '3.0': 'Arizona', '4.0': 'Arkansas', '5.0': 'California',\n",
    "                  '6.0': 'Colorado', '7.0': 'Connecticut', '8.0': 'Delaware', '9.0': 'Florida', '10.0': 'Georgia',\n",
    "                  '11.0': 'Hawaii', '12.0': 'Idaho', '13.0': 'Illinois', '14.0': 'Indiana', '15.0': 'Iowa', '16.0': 'Kansas',\n",
    "                  '17.0': 'Kentucky', '18.0': 'Louisiana', '19.0': 'Maine', '20.0': 'Maryland', '21.0':  'Massachusetts',\n",
    "                  '22.0': 'Michigan', '23.0': 'Minnesota', '24.0':  'Mississippi', '25.0' :  'Missouri', '26.0':  'Montana',\n",
    "                  '27.0': 'Nebraska', '28.0': 'Nevada', '29.0':'New Hampshire', '30.0':  'New Jersey', '31.0': 'New Mexico',\n",
    "                  '32.0': 'New York', '33.0': 'North Carolina', '34.0':  'North Dakota', '35.0':  'Ohio', '36.0':  'Oklahoma',\n",
    "                  '37.0': 'Oregon', '38.0': 'Pennsylvania', '39.0': 'Rhode Island', '40.0':  'South Carolina',\n",
    "                  '41.0': 'South Dakota', '42.0' :'Tennessee', '43.0':  'Texas', '44.0':  'Utah', '45.0':  'Vermont',\n",
    "                  '46.0': 'Virginia', '47.0': 'Washington', '48.0':  'West Virginia', '49.0':  'Wisconsin', '50.0':  'Wyoming'}\n",
    "    # semantic recoding \n",
    "    demW3 = survey_data['DemW3'].dropna().astype(str)\n",
    "    states = demW3.replace(state_dict)\n",
    "    # pop. distr. across states in survey_data\n",
    "    study_states = pd.DataFrame.from_dict(dict(Counter(states)), orient='index', columns=['study'])\n",
    "    study_states /= np.sum(study_states) \n",
    "    \n",
    "    # organise census data\n",
    "    census_states = census[['states', 'estimate_totalPop']]\n",
    "    census_states.set_index('states', inplace=True)\n",
    "    census_states = census_states.drop(['United States']) # remove bc not in survey data for norm\n",
    "    census_states = census_states.drop(['Puerto Rico']) # remove bc not in survey data for norm\n",
    "    # pop. distr. across states in census\n",
    "    census_states['census'] = census_states['estimate_totalPop']/np.sum(census_states['estimate_totalPop']) # norm\n",
    "    census_states.drop('estimate_totalPop', axis=1, inplace=True)\n",
    "    \n",
    "    # combine\n",
    "    combined = census_states.merge(study_states, left_index=True, right_index=True,  how = 'outer')\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "def get_nested_poli_data(survey_data):\n",
    "    \"\"\"\n",
    "    Gathers nseted political affiliation data from survey \n",
    "    -> links party affiliation and political leaning \n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data for one week\n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): nested political information\n",
    "    \"\"\"\n",
    "    survey = survey_data[['DemM6', 'DemM7']].astype(str)\n",
    "    survey = survey.set_index('DemM6')\n",
    "    \n",
    "    poli = {}\n",
    "    for i in set(survey.index):\n",
    "        to_count = survey['DemM7'].loc[str(i)]\n",
    "        if type(to_count) == str:\n",
    "            to_count = [to_count]\n",
    "        poli[str(i)] = dict(Counter(to_count))\n",
    "        \n",
    "    return poli\n",
    "\n",
    "\n",
    "def get_age_sex_data(survey_data, census_data):\n",
    "    \"\"\"\n",
    "    Gathers nested age and sex data from survey and census \n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey \n",
    "        census_data (pd.DataFrame): dataframe containing census information\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): survey data\n",
    "        df2 ((pd.DataFrame): census data\n",
    "        ages (list): list of age ranges as strings\n",
    "    \"\"\"\n",
    "    \n",
    "    survey_data = survey_data.set_index('PROLIFIC_PID')\n",
    "    \n",
    "    survey = survey_data[['prlfc_dem_age', 'DemC5']].astype(float)\n",
    "    survey.columns = ['Age', 'Sex']\n",
    "    bins= [i*5 for i in range(21)]\n",
    "    labels = [str(i*5) + '-' + str((i+1)*5-1) for i in range(20)]\n",
    "\n",
    "    survey['Age'] = pd.cut(survey['Age'], bins=bins, labels=labels, right=False)\n",
    "    survey = survey.set_index('Age')\n",
    "\n",
    "    ages = [value for value in labels if value in list(survey.index)]\n",
    "\n",
    "    df_dict = {'Age':ages, 'Male':[], 'Female':[]}\n",
    "\n",
    "    for age in ages:\n",
    "        to_count = survey['Sex'].loc[age]\n",
    "        if type(to_count) == np.float64:\n",
    "                to_count = [to_count]\n",
    "        counter = Counter(to_count)\n",
    "        df_dict['Male'].append(counter[1.0])\n",
    "        df_dict['Female'].append(-counter[2.0])\n",
    "\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    df = df.set_index('Age')\n",
    "    total = sum(df['Male']) - sum(df['Female'])\n",
    "    df['Male'] = df['Male']/total * 100\n",
    "    df['Female'] = df['Female']/total * 100\n",
    "\n",
    "    males = [i for i in census_data.columns if 'estimate_male_age_' in i and 'andOver' not in i]\n",
    "    females = [i for i in census_data.columns if 'estimate_female_age_' in i and 'andOver' not in i]\n",
    "    ages2 = [str(i*5) + '-' + str((i+1)*5-1) for i in range(3, 17)]\n",
    "    census_data = census_data.set_index('states')\n",
    "    male_data = census_data[males].loc['United States'].to_list()\n",
    "    female_data = [-i for i in census_data[females].loc['United States'].to_list()]\n",
    "    df2 = pd.DataFrame({'Ages':ages2, 'Male':male_data, 'Female':female_data})\n",
    "    total2 = sum(df2['Male']) - sum(df2['Female'])\n",
    "    df2['Male'] = df2['Male']/total2 * 100\n",
    "    df2['Female'] = df2['Female']/total2 * 100\n",
    "\n",
    "    return df, df2, ages\n",
    "\n",
    "def get_meadianAge_and_sex(survey_data):\n",
    "    \"\"\"\n",
    "    Extract median age and sex distribution in survey data\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey \n",
    "\n",
    "    Returns:\n",
    "        median_age (pd.DataFrame) \n",
    "        sex_perc (pd.DataFrame)\n",
    "        survey (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    # organise survey data\n",
    "    survey_data = survey_data.set_index('PROLIFIC_PID')\n",
    "    survey = pd.DataFrame()\n",
    "    survey = survey_data[['prlfc_dem_age', 'DemC5']].astype(float)\n",
    "    survey.columns = ['Age', 'Sex']\n",
    "    \n",
    "    median_age = survey['Age'].median()\n",
    "    sex_perc = sum(survey['Sex'] == 2.0)/len(survey)\n",
    "    return median_age, sex_perc, survey\n",
    "\n",
    "\n",
    "\n",
    "def get_race_data(survey_data):\n",
    "    \"\"\"\n",
    "    Gathers race and ethnicity data from survey data\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data \n",
    "\n",
    "    Returns:\n",
    "        (pd.DataFrame): combined race and ethnicity information\n",
    "    \"\"\"\n",
    "    \n",
    "    survey_data = survey_data.set_index('PROLIFIC_PID')\n",
    "    survey = survey_data[['DemC9', 'DemC8']].astype(str)\n",
    "    \n",
    "    raceEth = pd.DataFrame()\n",
    "    raceEth['ethnicity'] = survey['DemC8']\n",
    "    raceEth['ethnicity'] = raceEth['ethnicity'].replace({'1.0': 'Hispanic or Latinx', '2.0': 'Not Hispanic or Latinx',\n",
    "                                                         '3.0': 'Prefer not to disclose'})\n",
    "    raceEth['race'] = survey['DemC9']\n",
    "    raceEth['race'] = raceEth['race'].replace({'1.0': 'American Indian/Alaska Native', \n",
    "                                               '2.0': 'Asian', '3.0': 'Native Hawaiian or Other Pacific Islander',\n",
    "                                               '4.0': 'Black or African American', '5.0': 'White', '6.0': 'Multiracial',\n",
    "                                               '7.0': 'Other', '8.0': 'Prefer not to disclose'})\n",
    "        \n",
    "    return raceEth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "broken bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broken_bar(survey_data, census_data, ax1, ax2):\n",
    "    \"\"\"\n",
    "    Plots a broken bar graph for two sets of data (survey and census)\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data \n",
    "        census_data (pd.DataFrame): dataframe containing census information\n",
    "\n",
    "    Returns:\n",
    "        ax1, ax2: axes of the bar graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # load data and important graph values\n",
    "    df = get_state_data(survey_data, census_data)\n",
    "    df.loc[df['study'].isnull(), 'study'] = 0\n",
    "    df.rename(columns={'study':'survey'})\n",
    "    df = df.sort_values(by=['census'], ascending = False)\n",
    "    max_val = df.max().max()\n",
    "    cut = np.round(np.quantile(df, 0.88), 2) # 90% of values go into bottom graph\n",
    "    \n",
    "    ax1.set_title('Proportional Population by State')\n",
    "    \n",
    "    #set the y-limits on each subplot\n",
    "    ax1.set_ylim(cut, max_val)\n",
    "    ax2.set_ylim(0, cut)\n",
    "    \n",
    "    #set tick marks for upper plot \n",
    "    step1 = np.round((cut)/2, 3) \n",
    "    upper_yticks = np.arange(cut, max_val+step1, step1) \n",
    "    ax1.set_yticks(upper_yticks)\n",
    "    ax1.xaxis.set_ticks_position('none') \n",
    "    ax1.tick_params(labelbottom=False) \n",
    "    \n",
    "    #set ytick marks for lower plot \n",
    "    step2 = step1\n",
    "    lower_yticks = np.arange(0, cut, step2)\n",
    "    ax2.set_yticks(lower_yticks)\n",
    "    \n",
    "    #plot data into each subplot\n",
    "    df.plot(y=df.columns, kind=\"bar\", ax=ax1, width=0.8)\n",
    "    df.plot(y=df.columns, kind=\"bar\", ax=ax2, width=0.8, legend=False)\n",
    "    ax1.legend(['census', 'survey'])\n",
    "    #add figure labels\n",
    "    ax2.set_xlabel('State')\n",
    "    #fig.text(-0.01, 0.5, 'Proportion of US/study population', va='center', rotation='vertical')\n",
    "    \n",
    "    d = .01 # how big to make the diagonal lines in axes coordinates\n",
    "    # arguments to pass plot, just so we don't keep repeating them\n",
    "    kwargs = dict(transform=ax1.transAxes, color='r', clip_on=False)\n",
    "    ax1.plot((-d,+d),(-d*5,+d*5), **kwargs)      # top-left diagonal\n",
    "    ax1.plot((1-d,1+d),(-d*5,+d*5), **kwargs)    # top-right diagonal\n",
    "\n",
    "    kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "    ax2.plot((-d,+d),(1-d,1+d*2), **kwargs)   # bottom-left diagonal\n",
    "    ax2.plot((1-d,1+d),(1-d,1+d*2), **kwargs) # bottom-right diagonal\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "butterfly chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_sex_distribution(survey_data, census_data, ax):\n",
    "    \"\"\"\n",
    "    Plots a population pyramid for survey data with overlayed census data\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data for one week\n",
    "        census_data (pd.DataFrame): dataframe containing census information\n",
    "\n",
    "    Returns:\n",
    "        ax: axes of the chart\n",
    "    \"\"\"\n",
    "    \n",
    "    df, df2, ages = get_age_sex_data(survey_data, census_data)\n",
    "\n",
    "    order = ages[::-1]\n",
    "\n",
    "    bar_plot1 = sns.barplot(x='Male', y=df.index, data=df, order=order, lw=0, color='royalblue', alpha=0.7, ax= ax)\n",
    "    bar_plot2 = sns.barplot(x='Female', y=df.index, data=df, order=order, lw=0, color='indianred', alpha=0.7, ax= ax)\n",
    "    bar_plot3 = sns.barplot(x='Male', y='Ages', data=df2, order=order, lw=0, color='royalblue', alpha=0.4, ax= ax)\n",
    "    bar_plot4 = sns.barplot(x='Female', y='Ages', data=df2, order=order, lw=0, color='indianred', alpha=0.4, ax= ax)\n",
    "\n",
    "    max_val = abs(df[['Male', 'Female']]).max().max() * 1.05\n",
    "    ax.set_xlim((-max_val, max_val))\n",
    "    ax.set_xlabel('Percent of whole population')\n",
    "    custom_lines = [Line2D([0], [0], color='royalblue', alpha=0.7, linewidth=8),\n",
    "                   Line2D([0], [0], color='indianred', alpha=0.7, linewidth=8), \n",
    "                   Line2D([0], [0], color='royalblue', alpha=0.4, linewidth=8),\n",
    "                   Line2D([0], [0], color='indianred', alpha=0.4, linewidth=8)]\n",
    "    custom_labels = ['Male, survey', 'Female, survey', 'Male, census', 'Female, census']\n",
    "    ax.legend(custom_lines, custom_labels, loc='best')\n",
    "    ax.set_title('Age distribution by sex')\n",
    "    \n",
    "    return df, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nested pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nested_pie_poli(survey_data, party_estimate, ax,fontsize):\n",
    "    \"\"\"\n",
    "    Plots a nested pie chart of political affiliation and leaning \n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data \n",
    "\n",
    "    Returns:\n",
    "        ax: axes of the pie chart\n",
    "    \"\"\"\n",
    "    \n",
    "    poli = get_nested_poli_data(survey_data)\n",
    "\n",
    "    lean_names = {'1.0':'strongly liberal', '2.0':'moderately liberal', '3.0':'slightly liberal',\n",
    "             '4.0':'neutral', '5.0':'slightly conservative', '6.0':'moderately conservative', '7.0':'strongly conservative'}\n",
    "    \n",
    "    # Make data\n",
    "    party_names={'1.0':'Republican', '2.0':'Democrat', '3.0':'Independent', '4.0':'Other'}\n",
    "    group_names = [party_names[party] for party in sorted(poli)]\n",
    "    group_size=[sum(poli[i].values()) for i in sorted(poli)]\n",
    "\n",
    "    sortd = [sorted(poli[i]) for i in sorted(poli)]\n",
    "    subgroup_names = [val for sublist in sortd for val in sublist]\n",
    "    subgroup_size=[poli[i][j] for i in sorted(poli) for j in sorted(poli[i])]\n",
    "    \n",
    "    # Create colors\n",
    "    cols = [plt.cm.Reds, plt.cm.Blues, plt.cm.Purples, plt.cm.Greens]\n",
    "\n",
    "\n",
    "    # First pie (outside)\n",
    "    ax.axis('equal')\n",
    "    nums = [[(float(i)-1)/6 for i in li] for li in sortd]\n",
    "    #colours_ids = [plt.cm.Greys(nums[i][j]) for i in range(len(sortd)) for j in range(len(nums[i]))]\n",
    "    colours_ids = [plt.cm.Greys(nums[i][j]*.7+.15) for i in range(len(sortd)) for j in range(len(nums[i]))]\n",
    "    inner = ax.pie(subgroup_size, radius=1, colors=colours_ids, labeldistance=0.7)\n",
    "\n",
    "\n",
    "    # Second pie (inside)\n",
    "    colours = [cols[int(float(i))-1](0.7) for i in sorted(poli)]\n",
    "    exp_colors_inner= []\n",
    "    exp_colors_outer=['indianred', 'royalblue', 'mediumpurple', 'yellow']\n",
    "    for i_col, _ in enumerate(exp_colors_outer):\n",
    "        exp_colors_inner.append(sns.set_hls_values(matplotlib.colors.to_rgb(exp_colors_outer[i_col]),l=0.7))\n",
    "\n",
    "\n",
    "    mypie, mylables,prct = ax.pie(group_size, radius=(1-0.15), labels=group_names,labeldistance=0.5, colors=exp_colors_outer,autopct='%1.1f%%',pctdistance=0.85)\n",
    "    plt.setp(mypie,  edgecolor='black')\n",
    "    plt.setp(mylables, fontsize= fontsize, color = 'black')\n",
    "    plt.setp(prct, fontsize= fontsize, color = 'black')\n",
    "    \n",
    "    # third pie (inside)\n",
    "    colours = [cols[int(float(i))-1](0.7) for i in sorted(poli)]\n",
    "    mypie, mylables,prct = ax.pie(party_estimate['estimates'], radius=(1-0.5), labels=party_estimate['group_names'],labeldistance=0.5, colors=exp_colors_inner,autopct='%1.1f%%',pctdistance=0.85)\n",
    "    plt.setp(mypie,  edgecolor='white')\n",
    "    plt.setp(mylables, fontsize=fontsize, color = 'black')\n",
    "    plt.setp(prct, fontsize=fontsize, color = 'black')\n",
    "\n",
    "\n",
    "    custom_lines = [Line2D([0], [0], color=plt.cm.Greys(int(float(i)-1)/6), linewidth=8) for i in sorted(list(set(subgroup_names)))]\n",
    "    custom_labels = [lean_names[i] for i in sorted(list(set(subgroup_names)))]\n",
    "    ax.legend(custom_lines, custom_labels, loc='best')\n",
    "    ax.set_title('Partisanship and Political Leaning')\n",
    "    \n",
    "    return poli\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nested_pie_race(survey_data, census,ax, fontsize):\n",
    "    \"\"\"\n",
    "    Plots a nested pie chart of sample race vs census race\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data for one week\n",
    "        census (pd.DataFrame): dataframe containing census data\n",
    "    Returns:\n",
    "        ax: axes of the pie chart\n",
    "    \"\"\"\n",
    "    \n",
    "    race = get_race_data(survey_data)\n",
    "    #race.loc[race['ethnicity'] == 'Hispanic or Latinx', 'race'] = 'Hispanic or Latinx'\n",
    "    \n",
    "    race_names = race['race'].unique()\n",
    "    \n",
    "    census_race = pd.DataFrame()\n",
    "    census_race['race'] = race_names \n",
    "    census_race.loc[census_race['race'] == 'White', 'count'] = census['percent_oneRace_white'].iloc[-1]\n",
    "    census_race.loc[census_race['race'] == 'Black or African American', 'count'] = census['percent_oneRace_black'].iloc[-1]\n",
    "    census_race.loc[census_race['race'] == 'Asian', 'count'] = census['percent_oneRace_asian'].iloc[-1]\n",
    "    census_race.loc[census_race['race'] == 'American Indian/Alaska Native', 'count'] = census['percent_oneRace_nativeAm'].iloc[-1]\n",
    "    census_race.loc[census_race['race'] == 'Native Hawaiian or Other Pacific Islander', 'count'] = census['percent_oneRace_pacificIsl'].iloc[-1]\n",
    "    census_race.loc[census_race['race'] == 'Other', 'count'] = census['percent_oneRace_other'].iloc[-1]\n",
    "    census_race.loc[census_race['race'] == 'Multiracial', 'count'] = census['percent_more1race'].iloc[-1]\n",
    "    census_race.loc[census_race['count'].isnull(), 'count'] = 0\n",
    "    census_race = census_race.sort_values(by = 'race')\n",
    "   \n",
    "    exp_colors_outer = ['DarkViolet',  'SteelBlue','Lightcoral', 'MediumVioletRed','MediumSeaGreen',\n",
    "             'MediumPurple', 'Orange','DarkCyan','FireBrick' ]\n",
    "    \n",
    "    exp_colors_inner= []\n",
    "    for i_col, _ in enumerate(exp_colors_outer):\n",
    "        exp_colors_inner.append(sns.set_hls_values(matplotlib.colors.to_rgb(exp_colors_outer[i_col]),l=0.7))\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "    mypie, mylables,prct = ax.pie((race.groupby('race').race.count()/len(race))*100, radius=1, labeldistance=0.7, colors = exp_colors_outer, labels = race.race.value_counts().index,autopct='%1.1f%%',pctdistance=0.85)\n",
    "    plt.setp(mypie,  edgecolor='black')\n",
    "    plt.setp(mylables, fontsize= fontsize, color = 'black')\n",
    "    plt.setp(prct, fontsize= fontsize, color = 'black')\n",
    "    mypie, mylables,prct = ax.pie(census_race['count'], radius=0.5, labeldistance=0.7, colors = exp_colors_inner, labels = census_race['race'],autopct='%1.1f%%',pctdistance=0.85)\n",
    "    plt.setp(mypie,  edgecolor='white')\n",
    "    plt.setp(mylables, fontsize=fontsize, color = 'black')\n",
    "    plt.setp(prct, fontsize=fontsize, color = 'black')\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.93)\n",
    "\n",
    "    return census_race, race\n",
    "\n",
    "def nested_pie_ethnicity(survey_data, census,ax, fontsize):\n",
    "    \"\"\"\n",
    "    Plots a nested pie chart of sample ethnicity vs census ethnicity\n",
    "    \n",
    "    Args:\n",
    "        survey_data (pd.DataFrame): dataframe containing survey data for one week\n",
    "        census (pd.DataFrame): dataframe containing census data\n",
    "    Returns:\n",
    "        ax: axes of the pie chart\n",
    "    \"\"\"\n",
    "    \n",
    "    race = get_race_data(survey_data)\n",
    "    \n",
    "    eth_names = race['ethnicity'].unique()\n",
    "   \n",
    "    census_eth = pd.DataFrame()\n",
    "    census_eth['ethnicity'] = eth_names\n",
    "    census_eth.loc[census_eth['ethnicity'] == 'Hispanic or Latinx', 'count'] =census['percent_HispOrLat'].iloc[-1]\n",
    "    census_eth.loc[census_eth['ethnicity'] == 'Not Hispanic or Latinx', 'count'] =census['percent_NotHispOrLat'].iloc[-1]\n",
    "    census_eth.loc[census_eth['count'].isnull(), 'count'] = 0\n",
    "\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    exp_colors_outer = ['MediumVioletRed','Gold', 'RoyalBlue']\n",
    "    exp_colors_inner= []\n",
    "    for i_col, _ in enumerate(exp_colors_outer):\n",
    "        exp_colors_inner.append(sns.set_hls_values(matplotlib.colors.to_rgb(exp_colors_outer[i_col]),l=0.7))\n",
    "\n",
    "    mypie, mylables,prct = ax.pie(race.ethnicity.value_counts(), radius=1, labeldistance=0.7, colors = exp_colors_outer, \n",
    "                                  labels = eth_names,autopct='%1.1f%%',pctdistance=0.85)\n",
    "    plt.setp(mypie,  edgecolor='black')\n",
    "    plt.setp(mylables, fontsize= fontsize, color = 'black')\n",
    "    plt.setp(prct, fontsize= fontsize, color = 'black')\n",
    "    mypie, mylables,prct = ax.pie(census_eth['count'], radius=0.5, labeldistance=0.7, colors = exp_colors_inner, \n",
    "                                  labels = census_eth['ethnicity'],autopct='%1.1f%%',pctdistance=0.85,textprops={'size': 'x-large'})\n",
    "    plt.setp(mypie,  edgecolor='white')\n",
    "    plt.setp(mylables, fontsize=fontsize, color = 'black')\n",
    "    plt.setp(prct, fontsize=fontsize, color = 'black')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.93)\n",
    "\n",
    "    return race\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure: demographics  of core sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=40)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=30)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=30)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=30)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=30)    # legend fontsize\n",
    "plt.rc('figure', titlesize=50)  # fontsize of the figure title\n",
    "\n",
    "fig = plt.figure(figsize=(40, 30))\n",
    "\n",
    "gs = fig.add_gridspec(10,3)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "ax2 = fig.add_subplot(gs[1:4, :2])\n",
    "ax3 = fig.add_subplot(gs[:4, 2])\n",
    "ax4 = fig.add_subplot(gs[5:9, 0])\n",
    "ax5 = fig.add_subplot(gs[5:9, 1])\n",
    "ax6 = fig.add_subplot(gs[5:9, 2])\n",
    "\n",
    "####### state of residence ######\n",
    "broken_bar(core_data, census, ax1, ax2)\n",
    "ax1.set_yticklabels(['0.04','', '','','0.12','','','','0.20',''])\n",
    " # state dictionary\n",
    "state_dict = {'Alabama':'AL',  'Alaska':'AK',  'Arizona': 'AZ', 'Arkansas': 'AR', 'California':'CA',\n",
    "            'Colorado': 'CO', 'Connecticut':'CT','District of Columbia':'DC', 'Delaware': 'DE', 'Florida':'FL','Georgia':'GA',\n",
    "            'Hawaii':'HI', 'Idaho':'ID', 'Illinois':'IL',  'Indiana': 'IN',  'Iowa':'IA',  'Kansas':'KS',\n",
    "            'Kentucky':'KY', 'Louisiana':'LA', 'Maine':'ME', 'Maryland':'MD',  'Massachusetts':'MA',\n",
    "            'Michigan':'MI', 'Minnesota':'MN', 'Mississippi':'MS' , 'Missouri': 'MO',  'Montana':'MT',\n",
    "            'Nebraska':'NA','Nevada':'NV', 'New Hampshire':'NH', 'New Jersey':'NJ', 'New Mexico':'NM',\n",
    "            'New York':'NY','North Carolina':'NC',  'North Dakota':'ND', 'Ohio':'OH', 'Oklahoma':'OK',\n",
    "            'Oregon':'OR', 'Pennsylvania':'PA', 'Rhode Island':'RI',  'South Carolina':'SC',\n",
    "            'South Dakota':'SD', 'Tennessee':'TN', 'Texas':'TX', 'Utah':'UT', 'Vermont':'VT',\n",
    "            'Virginia':'VA',  'Washington':'WA',  'West Virginia':'WV',  'Wisconsin':'WI', 'Wyoming':'WY'}\n",
    "ax_xlables = ax2.get_xticklabels()\n",
    "new_lables = []\n",
    "for idx  in range(len(ax_xlables)):\n",
    "    new_lables.append(state_dict[ax_xlables[idx].get_text()])\n",
    "ax2.set_xticklabels(new_lables)\n",
    "\n",
    "#### page and sex #######\n",
    "age_surv, age_cens = age_sex_distribution(core_data, census, ax3)\n",
    "\n",
    "#### political affiliation #######\n",
    "# estimates taken from: https://news.gallup.com/poll/15370/party-affiliation.aspx\n",
    "party_estimates = pd.DataFrame()\n",
    "party_estimates['estimates'] = [27,31, 39,3]\n",
    "party_estimates['group_names'] = ['Republican', 'Democrat', 'Independent', 'Other']\n",
    "poli = nested_pie_poli(core_data, party_estimates, ax4,40)\n",
    "\n",
    "\n",
    "#### race and ethnicity #########\n",
    "census_race, race = mylables = nested_pie_race(core_data, census, ax5,  40)\n",
    "eth = nested_pie_ethnicity(core_data, census, ax6,40)\n",
    "\n",
    "\n",
    "# save as svg\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.05)\n",
    "plt.savefig(os.path.join('imgs', 'demw1-16.svg'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demographics of excluded and low completion rate subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sex_exl, _, ages = get_age_sex_data(excluded_data, census)\n",
    "age_sex_exl['Male'] = age_sex_exl['Male'].astype(float).abs().round(decimals=2)\n",
    "age_sex_exl['Female'] = age_sex_exl['Female'].astype(float).abs().round(decimals=2)\n",
    "age_sex_exl = age_sex_exl.rename(columns = {'Male': 'male excluded','Female': 'female excluded'})\n",
    "age_sex_exl['ages'] = ages\n",
    "\n",
    "age_sex_lowComp, _, ages = get_age_sex_data(lowCompl_data, census)\n",
    "age_sex_lowComp['Male'] = age_sex_lowComp['Male'].astype(float).abs().round(decimals=2)\n",
    "age_sex_lowComp['Female'] = age_sex_lowComp['Female'].astype(float).abs().round(decimals=2)\n",
    "age_sex_lowComp = age_sex_lowComp.rename(columns = {'Male': 'male low comp.','Female': 'female low comp.'})\n",
    "age_sex_lowComp['ages'] = ages\n",
    "\n",
    "age_sex_core, _, ages = get_age_sex_data(core_data, census)\n",
    "age_sex_core['Male'] = age_sex_core['Male'].astype(float).abs().round(decimals=2)\n",
    "age_sex_core['Female'] = age_sex_core['Female'].astype(float).abs().round(decimals=2)\n",
    "age_sex_core = age_sex_core.rename(columns = {'Male': 'male core','Female': 'female core'})\n",
    "age_sex_core['ages'] = ages\n",
    "\n",
    "\n",
    "age_sex = pd.merge(age_sex_core, age_sex_lowComp,  how='right', left_on=['ages'], right_on = ['ages'])\n",
    "age_sex = pd.merge(age_sex, age_sex_exl,  how='right', left_on=['ages'], right_on = ['ages'])\n",
    "age_sex = age_sex.append(age_sex.sum(), ignore_index=True)\n",
    "age_sex.loc[len(age_sex)-1,'ages'] = 'sum'\n",
    "age_sex = age_sex.set_index('ages')\n",
    "age_sex = age_sex.round(decimals=2)\n",
    "age_sex.to_csv(os.path.join('out_data','attrition_age_sex.csv'))\n",
    "\n",
    "# party affiliation and political leaning    \n",
    "party_exclude, polit_lean_exclude = poli_affil(excluded_data,'_exclude')\n",
    "party_low_comp_rate, polit_lean_low_comp_rate = poli_affil(lowCompl_data,'_lowCompl')\n",
    "party_core, polit_lean_core = poli_affil(core_data,'_core')\n",
    "\n",
    "party_combined = pd.merge(party_core, party_low_comp_rate, how = 'outer', left_index = True,right_index = True)\n",
    "party_combined = pd.merge(party_combined, party_exclude, how = 'outer', left_index = True,right_index = True)\n",
    "\n",
    "lean_combined = pd.merge(polit_lean_core, polit_lean_low_comp_rate, how = 'outer', left_index = True,right_index = True)\n",
    "lean_combined = pd.merge(lean_combined, polit_lean_exclude, how = 'outer', left_index = True,right_index = True)\n",
    "\n",
    "party_combined.to_csv(os.path.join('out_data', 'attrition_party.csv'))\n",
    "lean_combined.to_csv(os.path.join('out_data', 'attrition_polit_lean.csv'))\n",
    "\n",
    "\n",
    "#employment_income\n",
    "employment_exl, income_exl = employment_income(excluded_data,'_exclude')\n",
    "employment_lowCompl, income_lowCompl = employment_income(lowCompl_data,'_lowCompl')\n",
    "employment_core, income_core = employment_income(core_data,'_core')\n",
    "\n",
    "employment_combined = pd.merge(employment_core, employment_lowCompl, how = 'outer', left_index = True,right_index = True)\n",
    "employment_combined = pd.merge(employment_combined, employment_exl, how = 'outer', left_index = True,right_index = True)\n",
    "\n",
    "income_combined = pd.merge(income_core, income_lowCompl, how = 'outer', left_index = True,right_index = True)\n",
    "income_combined = pd.merge(income_combined, income_exl, how = 'outer', left_index = True,right_index = True)\n",
    "\n",
    "employment_combined.to_csv(os.path.join('out_data','attrition_employment.csv'))\n",
    "income_combined.to_csv(os.path.join('out_data','attrition_income.csv'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
