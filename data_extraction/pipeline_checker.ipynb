{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lookup files\n",
    "aligned = pd.read_excel('COVID_Qualtrics_items_scores_aligned.xlsx', 'items')\n",
    "lookup = pd.read_excel('COVID_Qualtrics_items_scores_aligned.xlsx', 'items_lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Pilot30', 'Week1', 'Week2', 'Week3', 'Week4']:\n",
    "    name = i\n",
    "    name2 = i\n",
    "    caps = name.upper()\n",
    "    \n",
    "    if name != 'Pilot30':\n",
    "        name = name + '/W' + name[4:] + \"_Qualtrics\"\n",
    "        \n",
    "    # load original data\n",
    "    text_file = \"./Working_Data/\" + name + \"/COVID19_first_PROLIFIC_\" + caps + \"_text_items.csv\"\n",
    "    text_items = pd.read_csv(text_file, encoding = \"ISO-8859-1\", dtype=str, keep_default_na=False, na_values='')\n",
    "    text_items = text_items.iloc[1:] # delete first row\n",
    "    text_items = text_items.applymap(str) # make all values strings\n",
    "    text_columns = text_items.columns[1:] # get columns\n",
    "    \n",
    "    # load cleaned data\n",
    "    clean_file = \"./output/cleaned_data/tmp/\" + name2 + \".csv\"\n",
    "    cleaned = pd.read_csv(clean_file, encoding = \"ISO-8859-1\", dtype=str, keep_default_na=False, na_values='') \n",
    "    cleaned = cleaned.iloc[1:] # delete first row\n",
    "    cleaned = cleaned.applymap(str) # make all values strings\n",
    "    cleaned_columns = cleaned.columns[1:] # get columns\n",
    "    \n",
    "    # init lists\n",
    "    list_ones = []\n",
    "    list_extra_nans = []\n",
    "    list_no_idea = []\n",
    "    \n",
    "    # iterate over columns\n",
    "    for col_num in range(len(text_columns)):\n",
    "        \n",
    "        # get column name for original and cleaned data\n",
    "        tcol = text_columns[col_num]\n",
    "        ccol = cleaned_columns[col_num]\n",
    "        \n",
    "        # get counts of values in the columns\n",
    "        tvals = text_items[tcol].value_counts()\n",
    "        cvals = cleaned[ccol].value_counts()\n",
    "        \n",
    "        \n",
    "        # if the count lists are different\n",
    "        if list(tvals) != list(cvals):\n",
    "            \n",
    "            # get list of unique values \n",
    "            tlist = list(text_items[tcol].unique())\n",
    "            clist = list(cleaned[ccol].unique())\n",
    "            \n",
    "            # get nan counts\n",
    "            tnan = 0\n",
    "            cnan = 0\n",
    "            \n",
    "            if 'nan' in tvals:\n",
    "                tnan = tvals['nan']\n",
    "            if 'nan' in cvals:\n",
    "                cnan = cvals['nan']\n",
    "            \n",
    "            # check if columns are different becuase of 1.0 vs 1\n",
    "            if (len(clist) == len(tlist) + 1) and '1.0' in clist and '1' in clist:\n",
    "                list_ones.append(ccol)\n",
    "\n",
    "            \n",
    "            # check if one column has more nans than the other\n",
    "            elif cnan > tnan:\n",
    "                list_extra_nans.append(ccol)\n",
    "            \n",
    "            # other\n",
    "            else:\n",
    "                list_no_idea.append(ccol)\n",
    "                \n",
    "    # write lists of incorrect columns to textfile             \n",
    "    f = open(\"./output/cleaned_data/test/errors_text_\" + name2 + \".txt\", \"w\")\n",
    "    \n",
    "    f.write(\"TWO WAYS TO WRITE ONE: 1 AND 1.0\\n\")\n",
    "    for i in list_ones:\n",
    "        f.write(str(i))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    f.write(\"\\nEXTRA NANS IN CLEANED\\n\")\n",
    "    for i in list_extra_nans:\n",
    "        f.write(str(i))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    f.write(\"\\nNO IDEA\\n\")\n",
    "    for i in list_no_idea:\n",
    "        f.write(str(i))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Pilot30', 'Week1', 'Week2', 'Week3', 'Week4']:\n",
    "    name = i\n",
    "    name2 = i\n",
    "    caps = name.upper()\n",
    "    caps_end = \"_num_items.csv\"\n",
    "        \n",
    "    if name == 'Pilot30':\n",
    "        caps_end = \"_number_items.csv\"\n",
    "\n",
    "    if name == 'Week1':\n",
    "        caps_end = \"_numbers_items.csv\"\n",
    "        \n",
    "    if name != 'Pilot30':\n",
    "        name = name + '/W' + name[4:] + \"_Qualtrics\"\n",
    "        \n",
    "    # load original data\n",
    "    text_file = \"./Working_Data/\" + name + \"/COVID19_first_PROLIFIC_\" + caps + caps_end\n",
    "    text_items = pd.read_csv(text_file, encoding = \"ISO-8859-1\", dtype=str)\n",
    "    text_items = text_items.iloc[1:] # delete first row\n",
    "    text_items = text_items.applymap(str) # make all values strings\n",
    "    text_columns = text_items.columns[1:] # get columns\n",
    "    \n",
    "    # load cleaned data\n",
    "    clean_file = \"./output/cleaned_data/tmp/\" + name2 + \".csv\"\n",
    "    cleaned = pd.read_csv(clean_file, encoding = \"ISO-8859-1\", dtype=str) \n",
    "    cleaned = cleaned.iloc[1:] # delete first row\n",
    "    cleaned = cleaned.applymap(str) # make all values strings\n",
    "    cleaned_columns = cleaned.columns[1:] # get columns\n",
    "    \n",
    "    # init lists\n",
    "    list_floats_vs_ints = []\n",
    "    list_missing_one = []\n",
    "    list_extra_nans = []\n",
    "    list_no_idea = []\n",
    "    \n",
    "    # iterate over columns\n",
    "    for col_num in range(len(text_columns)):\n",
    "        \n",
    "        # get column name for original and cleaned data\n",
    "        tcol = text_columns[col_num]\n",
    "        ccol = cleaned_columns[col_num]\n",
    "        \n",
    "        # get counts of values in the columns\n",
    "        tvals = text_items[tcol].value_counts()\n",
    "        cvals = cleaned[ccol].value_counts()\n",
    "        \n",
    "        # if the count lists are different\n",
    "        if list(tvals) != list(cvals):\n",
    "\n",
    "            # get list of unique values \n",
    "            tlist = list(text_items[tcol].unique())\n",
    "            clist = list(cleaned[ccol].unique())\n",
    "\n",
    "            # get nan counts\n",
    "            tnan = 0\n",
    "            cnan = 0\n",
    "\n",
    "            if 'nan' in tvals:\n",
    "                tnan = tvals['nan']\n",
    "            if 'nan' in cvals:\n",
    "                cnan = cvals['nan']\n",
    "\n",
    "            try:\n",
    "                tlist_ints = set([int(float(i)) for i in tlist if i != 'nan'])\n",
    "                clist_ints = set([int(float(i)) for i in clist if i != 'nan'])\n",
    "            except ValueError:\n",
    "                tlist_ints = set([int(float(i)) for i in tlist if i != 'nan'])\n",
    "                clist_ints = set([i for i in clist if i != 'nan'])\n",
    "                \n",
    "            # check if missing one value:\n",
    "            if len(tlist_ints) - len(clist_ints) == 1:\n",
    "                list_missing_one.append(ccol)\n",
    "            \n",
    "            # check if one column has more nans than the other\n",
    "            elif cnan > tnan:\n",
    "                list_extra_nans.append(ccol)\n",
    "                \n",
    "            # ignore if columns are different becuase of float vs int    \n",
    "            elif tlist_ints == clist_ints:\n",
    "                pass\n",
    "                \n",
    "            # ignore if just been reorded to be sequential\n",
    "            elif len(tlist_ints) == len(clist_ints):\n",
    "                pass\n",
    "            \n",
    "            # check if one-hot encoded\n",
    "            elif sorted(clist) == sorted(['nan', str(float(ccol[-1]))]):\n",
    "                pass\n",
    "            \n",
    "            # other\n",
    "            else:\n",
    "                list_no_idea.append(ccol)\n",
    "                \n",
    "    # write lists of incorrect columns to textfile             \n",
    "    f = open(\"./output/cleaned_data/test/errors_numbers_\" + name2 + \".txt\", \"w\")\n",
    "        \n",
    "    f.write(\"MISSING ONE VALUE IN CLEANED\\n\")\n",
    "    for i in list_missing_one:\n",
    "        f.write(str(i))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    f.write(\"\\nEXTRA NANS IN CLEANED\\n\")\n",
    "    for i in list_extra_nans:\n",
    "        f.write(str(i))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    f.write(\"\\nNO IDEA\\n\")\n",
    "    for i in list_no_idea:\n",
    "        f.write(str(i))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
