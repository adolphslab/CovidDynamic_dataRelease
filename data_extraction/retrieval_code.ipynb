{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request = pd.read_csv('./Working_Data/COVIDDYNAMIC_Internal_Requests.csv', names=['label', 'details', 'extra'])\n",
    "lookup = pd.read_excel('./Working_Data/Combined_Request_Lookup.xlsx', sheet_name='Qualt_lookup', index_col='Qualtrics_Request_Variable')\n",
    "lookup_direc = pd.read_excel('./Working_Data/Combined_Request_Lookup.xlsx', sheet_name='Directory')\n",
    "lookup_direc = lookup_direc.rename(columns=lookup_direc.iloc[0]).drop(lookup_direc.index[0])\n",
    "lookup_direc.set_index('Request_Label', inplace=True)\n",
    "data = pd.read_csv('./output/Wave1-17_A-N_release.csv', encoding = \"ISO-8859-1\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Wave</th>\n",
       "      <th>Request_Label</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qualtrics_Request_Variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVD_Data_1_1</th>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>Supplemental Data - COVID-19 cases &amp; deaths by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVD_Data_2_1</th>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>Supplemental Data - COVID-19 cases &amp; deaths by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVD_Data_3_1</th>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>Supplemental Data - COVID-19 cases &amp; deaths by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVD_Data_4_1</th>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>4 - A</td>\n",
       "      <td>CVD_Data_Cases</td>\n",
       "      <td>Supplemental Data - COVID-19 cases &amp; deaths by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFPS36v2_2</th>\n",
       "      <td>Conte</td>\n",
       "      <td>E</td>\n",
       "      <td>GFPS36v2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFPS37v2_1</th>\n",
       "      <td>Prolific</td>\n",
       "      <td>8.0</td>\n",
       "      <td>GFPS37v2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFPS37v2_2</th>\n",
       "      <td>Conte</td>\n",
       "      <td>E</td>\n",
       "      <td>GFPS37v2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFPS38v2_1</th>\n",
       "      <td>Prolific</td>\n",
       "      <td>8.0</td>\n",
       "      <td>GFPS38v2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFPS38v2_2</th>\n",
       "      <td>Conte</td>\n",
       "      <td>E</td>\n",
       "      <td>GFPS38v2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Group   Wave   Request_Label  \\\n",
       "Qualtrics_Request_Variable                                          \n",
       "NaN                                    NaN    NaN             NaN   \n",
       "CVD_Data_1_1                CVD_Data_Cases    1.0  CVD_Data_Cases   \n",
       "CVD_Data_2_1                CVD_Data_Cases    2.0  CVD_Data_Cases   \n",
       "CVD_Data_3_1                CVD_Data_Cases    3.0  CVD_Data_Cases   \n",
       "CVD_Data_4_1                CVD_Data_Cases  4 - A  CVD_Data_Cases   \n",
       "...                                    ...    ...             ...   \n",
       "GFPS36v2_2                           Conte      E        GFPS36v2   \n",
       "GFPS37v2_1                        Prolific    8.0        GFPS37v2   \n",
       "GFPS37v2_2                           Conte      E        GFPS37v2   \n",
       "GFPS38v2_1                        Prolific    8.0        GFPS38v2   \n",
       "GFPS38v2_2                           Conte      E        GFPS38v2   \n",
       "\n",
       "                                                                         Item  \n",
       "Qualtrics_Request_Variable                                                     \n",
       "NaN                                                                       NaN  \n",
       "CVD_Data_1_1                Supplemental Data - COVID-19 cases & deaths by...  \n",
       "CVD_Data_2_1                Supplemental Data - COVID-19 cases & deaths by...  \n",
       "CVD_Data_3_1                Supplemental Data - COVID-19 cases & deaths by...  \n",
       "CVD_Data_4_1                Supplemental Data - COVID-19 cases & deaths by...  \n",
       "...                                                                       ...  \n",
       "GFPS36v2_2                  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...  \n",
       "GFPS37v2_1                  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...  \n",
       "GFPS37v2_2                  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...  \n",
       "GFPS38v2_1                  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...  \n",
       "GFPS38v2_2                  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...  \n",
       "\n",
       "[1699 rows x 4 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group                                                   Prolific\n",
       "Wave                                                        17.0\n",
       "Request_Label                                          CVD_Consp\n",
       "Item             COVID_Conspiracies-Prolific-Wave 17-N (7/24/21)\n",
       "Name: CVD_Consp_P_17, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.loc['CVD_Consp_P_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20031    2.0\n",
       "20032    3.0\n",
       "20033    1.0\n",
       "20034    1.0\n",
       "20035    4.0\n",
       "        ... \n",
       "20665    3.0\n",
       "20666    1.0\n",
       "20667    3.0\n",
       "20668    4.0\n",
       "20669    4.0\n",
       "Name: Cnsp1_1, Length: 639, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['wave']=='17', 'Cnsp1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conte_waves = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N']\n",
    "all_prolific_waves = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '15b', '16', '17']\n",
    "task_dir = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\PreProcessed_Data\\tasks'\n",
    "\n",
    "def extract_uvn(request_label, i):\n",
    "    # get unified variable name(s)\n",
    "    try:\n",
    "        unified_variable_names = lookup_direc['unified_variable_names'].loc[request_label]\n",
    "        if type(unified_variable_names) == str:\n",
    "            unified_variable_names = [unified_variable_names]\n",
    "        else:\n",
    "            unified_variable_names = list(unified_variable_names)\n",
    "        return unified_variable_names\n",
    "    except KeyError:\n",
    "        print('{:<30s}{:<30s}{:10s}'.format(str(i), str(request_label), 'x'))\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def extract_data(request):\n",
    "    variables_and_waves = {}\n",
    "    print('{:<30s}{:<30s}{:10s}'.format('UNV', 'request_label', 'x'))\n",
    "    print('========================================================')\n",
    "    for i in request['label'].loc[5:]:\n",
    "        try:\n",
    "            wave = lookup['Wave'].loc[i]\n",
    "            \n",
    "            current_label = lookup['Request_Label'].loc[i]\n",
    "            #print(current_label)\n",
    "            #print(wave)\n",
    "            if wave == 'All':\n",
    "                #print(current_label)\n",
    "                #print(lookup['Group'].loc[i])\n",
    "                if lookup['Group'].loc[i] == 'Prolific':\n",
    "                    selected_waves = all_prolific_waves.copy()\n",
    "                    #print(selected_waves)\n",
    "                if lookup['Group'].loc[i] == 'Conte':\n",
    "                    selected_waves = all_conte_waves.copy()\n",
    "                    #print(selected_waves)\n",
    "                    #print(all_conte_waves)\n",
    "                #print(selected_waves)\n",
    "                \n",
    "\n",
    "                UVN = extract_uvn(current_label, i)\n",
    "                if UVN:\n",
    "                    for var in UVN:\n",
    "                        if var in variables_and_waves.keys():\n",
    "                            variables_and_waves[var] = variables_and_waves[var] + selected_waves\n",
    "                        else:\n",
    "                            variables_and_waves[var] = selected_waves\n",
    "            else:\n",
    "                UVN = extract_uvn(current_label, i)\n",
    "                if UVN:\n",
    "                    for var in UVN:\n",
    "                        if var in variables_and_waves.keys():\n",
    "                            if type(wave) == int or type(wave) == float:\n",
    "                                if str(int(wave)) not in variables_and_waves[var]:\n",
    "                                    variables_and_waves[var].append(str(int(wave)))\n",
    "                            else:\n",
    "                                if str(wave) not in variables_and_waves[var]:\n",
    "                                    variables_and_waves[var].append(str(wave))\n",
    "                        else:\n",
    "                            if type(wave) == int or type(wave) == float:\n",
    "                                variables_and_waves[var] = [str(int(wave))]\n",
    "                            else:\n",
    "                                variables_and_waves[var] = [str(wave)]\n",
    "        except (KeyError, ValueError):\n",
    "            print('{:<30s}{:<30s}{:10s}{:10s}'.format(str(i), current_label, 'x', str(wave)))\n",
    "            continue\n",
    "    return variables_and_waves\n",
    "\n",
    "def crop_data(request):\n",
    "    variables_and_waves = extract_data(request)\n",
    "    # Debug\n",
    "    #print(variables_and_waves)\n",
    "    variables_and_waves['V4'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['V3'] = all_conte_waves + all_prolific_waves\n",
    "\n",
    "    # adding adminstration variables\n",
    "    variables_and_waves['DO_Event_Surveys'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['DO_Main_Surveys'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['TASK1'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['TASK2'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['TASK3'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['TASK4'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['TASK5'] = all_conte_waves + all_prolific_waves\n",
    "    variables_and_waves['RW27'] = all_conte_waves + all_prolific_waves\n",
    "    \n",
    "    # Adding quality measures\n",
    "    quality_variables = lookup_direc.loc['Quality','unified_variable_names'].values\n",
    "    for var in quality_variables:\n",
    "        variables_and_waves[var] = all_conte_waves + all_prolific_waves\n",
    "        \n",
    "    columns = [col for col in variables_and_waves.keys() if col in data.columns]\n",
    "    #print(columns)\n",
    "    columns.extend(['wave', 'PROLIFIC_PID'])\n",
    "    print('\\nThese columns were not found in the data:')\n",
    "    for i in [col for col in variables_and_waves.keys() if col not in data.columns]:\n",
    "        print(i)\n",
    "\n",
    "    output_data = data[columns]\n",
    "    output_data['wave'] =  output_data['wave'].astype(str)\n",
    "    output_data.set_index('wave', inplace=True)\n",
    "    \n",
    "    waves = list(set(list(output_data.index)))\n",
    "    print(waves)\n",
    "    for col in output_data.columns:\n",
    "        if col == 'PROLIFIC_PID':\n",
    "            continue\n",
    "        to_nan = [w for w in waves if w not in variables_and_waves[col]]\n",
    "        if col == 'Cnsp1_1':\n",
    "            print(variables_and_waves[col])\n",
    "        if col == 'Assist_EtOH_raw':\n",
    "            print(variables_and_waves['Assist_EtOH_raw'][0])\n",
    "            print(to_nan)\n",
    "        output_data[col].loc[to_nan] = np.nan\n",
    "    \n",
    "    output_data.insert(0, 'wave', output_data.index)\n",
    "    output_data.set_index('PROLIFIC_PID', inplace=True)\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "\n",
    "def clean_up(request):\n",
    "    request = request.loc[request['extra'] == \"1\"]\n",
    "    data = crop_data(request)\n",
    "    columns = data.columns.tolist()\n",
    "    columns.remove('wave')\n",
    "    columns.remove('V4')\n",
    "    subset = data.dropna(subset=columns, how='all')\n",
    "    return subset\n",
    "\n",
    "def inspect_request(filename):\n",
    "    new_request = pd.read_csv(filename).T\n",
    "    new_request = new_request.reset_index()\n",
    "    new_request = new_request.iloc[17:]\n",
    "    return new_request\n",
    "\n",
    "def process_request(request_filename, request_col, save_filename):\n",
    "    new_request = pd.read_csv(request_filename).T\n",
    "    new_request = new_request.reset_index()\n",
    "    new_request = new_request.iloc[17:]\n",
    "    request = new_request.iloc[:, [0,1,request_col]].rename(columns={'index': 'label', 0: \"details\", request_col-1: \"extra\"})\n",
    "    request = request.loc[request['extra'] == \"1\"]\n",
    "    request.to_csv(save_filename)\n",
    "    return request\n",
    "\n",
    "def export_tasks(request, filename):\n",
    "    task_cols = list(request.loc[request.label.str.startswith('Task').values, 'label'].values)\n",
    "    \n",
    "    # remove PGG from request for now\n",
    "    for col_idx, i_col in enumerate(task_cols):\n",
    "        if i_col.startswith('Task_C_PGG') | i_col.startswith('Task_P_PGG'):\n",
    "            task_cols.pop(col_idx)\n",
    "        \n",
    "    filename = filename.strip('data.csv')\n",
    "    filename = '.' + filename\n",
    "    task = ''\n",
    "    wave = []\n",
    "    group = ''\n",
    "    data = pd.DataFrame()\n",
    "    for i_idx, i_task, in enumerate(task_cols):\n",
    "        substr_idx = [m.start() for m in re.finditer('_', i_task)]\n",
    "        if i_idx+1 < len(task_cols):\n",
    "            i_task_1 = task_cols[i_idx+1]\n",
    "            next_group = i_task_1[substr_idx[0]+1:substr_idx[1]]\n",
    "            next_task = i_task_1[substr_idx[1]+1:substr_idx[2]]\n",
    "        else:\n",
    "            i_task_1 = ''\n",
    "            next_group = ''\n",
    "            next_task = ''\n",
    "        curr_group = i_task[substr_idx[0]+1:substr_idx[1]]\n",
    "        curr_task = i_task[substr_idx[1]+1:substr_idx[2]]\n",
    "        curr_wave = i_task[substr_idx[2]+1:]\n",
    "        if curr_wave == '99':\n",
    "            task = curr_task\n",
    "            group = curr_group\n",
    "            data = pd.read_csv(task_dir + '\\\\' + task + '_' + group +'.csv')\n",
    "            data.to_csv(filename + task + '_' + group + '.csv')\n",
    "            data = pd.DataFrame()\n",
    "        elif (task != curr_task) | (group != curr_group):\n",
    "            task = curr_task\n",
    "            group = curr_group\n",
    "            tmp_data = pd.read_csv(task_dir + task + '_' + group +'.csv',index=False)\n",
    "            wave_col = tmp_data.columns[tmp_data.columns.str.endswith('wave')].values[0]\n",
    "            if group =='P':\n",
    "                curr_wave = int(curr_wave)\n",
    "            data = tmp_data.loc[tmp_data[wave_col] == curr_wave, :]\n",
    "            data.to_csv(filename + task + '_' + group + '.csv',index=False)\n",
    "        elif (task == curr_task) & (group == curr_group):\n",
    "            wave_data = tmp_data.loc[tmp_data[wave_col] == int(curr_wave), :]\n",
    "            data = data.append(wave_data)\n",
    "            if (curr_task != next_task) | (curr_group != next_group):              \n",
    "                data.to_csv(filename + task + '_' + group + '.csv', index=False)\n",
    "                data = pd.DataFrame()\n",
    "                \n",
    "\n",
    "def export(request, filename, data):\n",
    "    \n",
    "    # Export task data\n",
    "    export_tasks(request, filename)\n",
    "    \n",
    "    # Export main data\n",
    "    data = crop_data(request)\n",
    "    \n",
    "    #print(data.loc[data['wave']=='17', 'Cnsp1_1'])\n",
    "    \n",
    "    columns = data.columns.tolist()\n",
    "    # remove admin columns\n",
    "    columns.remove('wave')\n",
    "    columns.remove('V4')\n",
    "    columns.remove('V3')\n",
    "    columns.remove('DO_Event_Surveys')\n",
    "    columns.remove('DO_Main_Surveys')\n",
    "    columns.remove('TASK1')\n",
    "    columns.remove('TASK2')\n",
    "    columns.remove('TASK3')\n",
    "    columns.remove('TASK4')\n",
    "    columns.remove('TASK5')\n",
    "    columns.remove('RW27')\n",
    "    \n",
    "    quality_variables = lookup_direc.loc['Quality','unified_variable_names'].values\n",
    "    for var in quality_variables:\n",
    "        try:\n",
    "            columns.remove(var)\n",
    "        except:\n",
    "            print(var)\n",
    "            continue\n",
    "\n",
    "    subset = data.dropna(subset=columns, how='all')\n",
    "    subset = subset.fillna('NA')\n",
    "    subset.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_path = r\"C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Invest_2</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>A year like no other: Longitudinal trajectorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Invest_3</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>Teresa Lopez-Castro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Invest_4</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>The City College of New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Invest_5</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>lopezcastro.phd.ccny@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Other_Investigators#1_1_1</td>\n",
       "      <td>All data will be distributed via Box to the PI...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>GFPS36v2_2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>GFPS37v2_1</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>GFPS37v2_2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>GFPS38v2_1</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>GFPS38v2_2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1617 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  \\\n",
       "17                     Invest_2   \n",
       "18                     Invest_3   \n",
       "19                     Invest_4   \n",
       "20                     Invest_5   \n",
       "21    Other_Investigators#1_1_1   \n",
       "...                         ...   \n",
       "1629                 GFPS36v2_2   \n",
       "1630                 GFPS37v2_1   \n",
       "1631                 GFPS37v2_2   \n",
       "1632                 GFPS38v2_1   \n",
       "1633                 GFPS38v2_2   \n",
       "\n",
       "                                                      0  \\\n",
       "17    Prior to submitting a data-request, the COVID-...   \n",
       "18    Prior to submitting a data-request, the COVID-...   \n",
       "19    Prior to submitting a data-request, the COVID-...   \n",
       "20    Prior to submitting a data-request, the COVID-...   \n",
       "21    All data will be distributed via Box to the PI...   \n",
       "...                                                 ...   \n",
       "1629  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1630  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1631  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1632  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1633  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "\n",
       "                                                      1  \n",
       "17    A year like no other: Longitudinal trajectorie...  \n",
       "18                                  Teresa Lopez-Castro  \n",
       "19                         The City College of New York  \n",
       "20                       lopezcastro.phd.ccny@gmail.com  \n",
       "21                                                  NaN  \n",
       "...                                                 ...  \n",
       "1629                                                  1  \n",
       "1630                                                  1  \n",
       "1631                                                  1  \n",
       "1632                                                  1  \n",
       "1633                                                  1  \n",
       "\n",
       "[1617 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Teresa_Lopez_Castro_A_year_like_no_other\\request.csv'\n",
    "request = inspect_request(request_filename)\n",
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_4                  Unemployment_Stats            x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_4                  Unemployment_Stats            x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_4                  Unemployment_Stats            x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_4                  Unemployment_Stats            x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_4                  Unemployment_Stats            x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_4                  Unemployment_Stats            x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_4                  Unemployment_Stats            x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_10_4                 Unemployment_Stats            x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_4                 Unemployment_Stats            x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_4                 Unemployment_Stats            x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_4                 Unemployment_Stats            x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_4                 Unemployment_Stats            x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_4                 Unemployment_Stats            x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_4                 Unemployment_Stats            x         \n",
      "CVD_Data_17_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_17_4                 Unemployment_Stats            x         \n",
      "EMS_P_2_1                     EMSC                          x         1.0       \n",
      "EMS_P_2_2                     EMSC                          x         1.0       \n",
      "EMS_P_4_1                     EMSC                          x         3.0       \n",
      "EMS_P_4_2                     EMSC                          x         3.0       \n",
      "EMS_P_5_1                     EMSC                          x         3.0       \n",
      "EMS_P_5_2                     EMSC                          x         3.0       \n",
      "EMS_P_10_1                    EMSC                          x         9.0       \n",
      "EMS_P_10_2                    EMSC                          x         9.0       \n",
      "Task_P_BIAT_99                BIAT                          x         \n",
      "Task_P_IAT_99                 IAT                           x         \n",
      "Task_P_AMP_99                 AMP                           x         \n",
      "Task_P_TR1_99                 TR1                           x         \n",
      "Task_P_ATT_99                 ATT                           x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "own_prev_choice\n",
      "p2_prev_choice\n",
      "p3_prev_choice\n",
      "p4_prev_choice\n",
      "own_outcome\n",
      "p2_outcome\n",
      "p3_outcome\n",
      "p4_outcome\n",
      "choice\n",
      "RT\n",
      "prev_wave\n",
      "mismatch_dem_age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\anaconda3\\envs\\g\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\andyl\\anaconda3\\envs\\g\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', 'N', '15', 'K', '5', 'I', 'L', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '11', '6', '12', '2', 'H']\n",
      "['17']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-229-a629d9d259f2>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 1. Uri, Tom: Relation between Expressed Social Norms of COVID-19, Social Factors & Actual Preventative Behaviors\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Uri_Maoz_Tom_Relation_between_Expressed_Social_Norms\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Uri_Maoz_Tom_Relation_between_Expressed_Social_Norms/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "LEC_C_2                       LEC                           x         17.0      \n",
      "NIH_C_1                       NIH                           x         nan       \n",
      "NIH_C_3                       NIH                           x         nan       \n",
      "PSS_C_2                       PSS                           x         nan       \n",
      "PSS_C_4                       PSS                           x         nan       \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', '15', 'K', '5', 'I', 'L', 'M', '15b', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-230-9c6b02db8b8d>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 2. Teresa Lopez-Castro 5/24: A year like no other\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Teresa_Lopez_Castro_A_year_like_no_other\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Teresa_Lopez_Castro_A_year_like_no_other/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_4                  Unemployment_Stats            x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_4                  Unemployment_Stats            x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_4                  Unemployment_Stats            x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_4                  Unemployment_Stats            x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_4                  Unemployment_Stats            x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_4                  Unemployment_Stats            x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_4                  Unemployment_Stats            x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_10_4                 Unemployment_Stats            x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_4                 Unemployment_Stats            x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_4                 Unemployment_Stats            x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_4                 Unemployment_Stats            x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_4                 Unemployment_Stats            x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_4                 Unemployment_Stats            x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_4                 Unemployment_Stats            x         \n",
      "CVD_Data_17_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_17_4                 Unemployment_Stats            x         \n",
      "NIH_C_1                       NIH                           x         nan       \n",
      "NIH_C_3                       NIH                           x         nan       \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-231-d030c309060f>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 3. Marina Weiss request 5/24: Longitudinal Impacts of Discrimination on Depressive Symptomatology in Racial/Ethnic Minorities During the COVID and Racial Injustice Pandemics\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Marina_Weiss_Longitudinal_Impacts_of_Discrimination\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Marina_Weiss_Longitudinal_Impacts_of_Discrimination/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "Task_P_Consp_99               CONS_TSK                      x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', 'N', '15', 'K', '5', 'I', 'L', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '11', '6', '12', '2', 'H']\n",
      "['17']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-232-18ace1d6e54e>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 4. Andy 5/5: Conspiracy Theory\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Andy_Liang_Uncovering_Heterogeneity_within_Conspiracy_Theorists\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Andy_Liang_Uncovering_Heterogeneity_within_Conspiracy_Theorists/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Andy_Liang_Uncovering_Heterogeneity_within_Conspiracy_Theorists\\request.csv'\n",
    "#request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Nina_Memory\\request.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>details</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>CVD_Consp_P_17</td>\n",
       "      <td>COVID Conspiracies Questionnaire - Prolific - ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                            details extra\n",
       "308  CVD_Consp_P_17  COVID Conspiracies Questionnaire - Prolific - ...     1"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.loc[request['label']=='CVD_Consp_P_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_4                  Unemployment_Stats            x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_4                  Unemployment_Stats            x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_4                  Unemployment_Stats            x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_4                  Unemployment_Stats            x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_4                  Unemployment_Stats            x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_4                  Unemployment_Stats            x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_4                  Unemployment_Stats            x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_10_4                 Unemployment_Stats            x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_4                 Unemployment_Stats            x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_4                 Unemployment_Stats            x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_4                 Unemployment_Stats            x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_4                 Unemployment_Stats            x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_4                 Unemployment_Stats            x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_4                 Unemployment_Stats            x         \n",
      "DSR_C_1                       nan                           x         \n",
      "H_E_C_1                       H_E                           x         nan       \n",
      "LEC_C_2                       LEC                           x         12.0      \n",
      "NIH_C_1                       NIH                           x         nan       \n",
      "NIH_C_3                       NIH                           x         nan       \n",
      "PSS_C_2                       PSS                           x         nan       \n",
      "PSS_C_4                       PSS                           x         nan       \n",
      "SPS_C_4                       SPS                           x         nan       \n",
      "VSA_C_1                       VSA                           x         nan       \n",
      "VSA_C_4                       VSA                           x         nan       \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyl\\anaconda3\\envs\\g\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\andyl\\anaconda3\\envs\\g\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', 'N', '15', 'K', '5', 'I', 'L', 'M', '15b', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-235-0ba2f9b77d3a>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 5. Nina: Memory\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Nina_Memory\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Nina_Memory/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "\n",
      "These columns were not found in the data:\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-236-d5253ba05ca0>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 6. Damian: EPII\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Damian_Stanley_EPII\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Damian_Stanley_EPII/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "\n",
      "These columns were not found in the data:\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', 'N', '15', 'K', '5', 'I', 'L', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-237-d8a33767062b>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 7. Teresa: Longitudinal_Trajectories_and_Predictors_of_Substance_Use_during_COVID\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Teresa_Lopez_Castro_Longitudinal_Trajectories_and_Predictors_of_Substance_Use_during_COVID\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Teresa_Lopez_Castro_Longitudinal_Trajectories_and_Predictors_of_Substance_Use_during_COVID/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_17_3                 CVD_Data_Protest              x         \n",
      "EMS_P_2_1                     EMSC                          x         1.0       \n",
      "EMS_P_2_2                     EMSC                          x         1.0       \n",
      "EMS_P_4_1                     EMSC                          x         3.0       \n",
      "EMS_P_4_2                     EMSC                          x         3.0       \n",
      "EMS_P_5_1                     EMSC                          x         3.0       \n",
      "EMS_P_5_2                     EMSC                          x         3.0       \n",
      "EMS_P_10_1                    EMSC                          x         9.0       \n",
      "EMS_P_10_2                    EMSC                          x         9.0       \n",
      "Task_P_BIAT_99                BIAT                          x         \n",
      "Task_P_AMP_99                 AMP                           x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-238-26ec6d50ceb8>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 8. Damian: Investigating the Impact of COVID-19 and the Events of 2020 on Race Attitudes in the United  States\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Damian_Stanley_Impact_of_COVID-19_and_the_Events_of_2020_on_Race_Attitudes\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Damian_Stanley_Impact_of_COVID-19_and_the_Events_of_2020_on_Race_Attitudes/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "\n",
      "These columns were not found in the data:\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "8\n",
      "['14', 'F', '3', 'N', '15', 'K', '5', 'I', 'L', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-239-c5b432a89a65>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 9. Marie Christine: Resilience, Self, and Mental Health: protective factors and risk factors in acute, then chronic stress\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Marie_Christine_Resilience\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Marie_Christine_Resilience/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-240-2be4b09fbd7e>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 10. Mike: The Impact of Psychological Traits, Political Attitudes, and COVID-Specific Concerns on Trust and Compliance in the COVID-19 Pandemic\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Mike_Alverez_The_Impact_of_Psychological_Traits_Political_Attitudes_and_COVID-Specific_Concerns\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Mike_Alverez_The_Impact_of_Psychological_Traits_Political_Attitudes_and_COVID-Specific_Concerns/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "EMS_P_2_1                     EMSC                          x         1.0       \n",
      "EMS_P_2_2                     EMSC                          x         1.0       \n",
      "EMS_P_4_1                     EMSC                          x         3.0       \n",
      "EMS_P_4_2                     EMSC                          x         3.0       \n",
      "EMS_P_5_1                     EMSC                          x         3.0       \n",
      "EMS_P_5_2                     EMSC                          x         3.0       \n",
      "EMS_P_10_1                    EMSC                          x         9.0       \n",
      "EMS_P_10_2                    EMSC                          x         9.0       \n",
      "\n",
      "These columns were not found in the data:\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-241-ec174c11638b>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 11. Yue: Evaluation of metrics for identifying and distinguishing psychological states from traits using COVID-dynamic dataset\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Yue_Xu_Evaluation_of_metrics_for_identifying_and_distinguishing_psychological_states_from_traits\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Yue_Xu_Evaluation_of_metrics_for_identifying_and_distinguishing_psychological_states_from_traits/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_4                  Unemployment_Stats            x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_4                  Unemployment_Stats            x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_4                  Unemployment_Stats            x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_4                  Unemployment_Stats            x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_4                  Unemployment_Stats            x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_4                  Unemployment_Stats            x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_4                  Unemployment_Stats            x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_10_4                 Unemployment_Stats            x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_4                 Unemployment_Stats            x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_4                 Unemployment_Stats            x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_4                 Unemployment_Stats            x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_4                 Unemployment_Stats            x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_4                 Unemployment_Stats            x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_4                 Unemployment_Stats            x         \n",
      "CVD_Data_17_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_17_4                 Unemployment_Stats            x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-242-fe170184991e>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 12. Yanting: Emotion Projects\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Yanting_Han_Emotion_Projects\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Yanting_Han_Emotion_Projects/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "DSR_C_1                       nan                           x         \n",
      "EmoSp_C_2                     EmoSp                         x         nan       \n",
      "EmoSp_C_4                     EmoSp                         x         nan       \n",
      "EMS_C_2_1                     EMSC                          x         A         \n",
      "EMS_C_2_2                     EMSC                          x         A         \n",
      "EMS_C_4_1                     EMSC                          x         B         \n",
      "EMS_C_4_2                     EMSC                          x         B         \n",
      "EMS_C_5_1                     EMSC                          x         B         \n",
      "EMS_C_5_2                     EMSC                          x         B         \n",
      "EMS_C_10_1                    EMSC                          x         F         \n",
      "EMS_C_10_2                    EMSC                          x         F         \n",
      "H_E_C_1                       H_E                           x         nan       \n",
      "LEC_C_2                       IPDS                          x         M         \n",
      "NIH_C_1                       NIH                           x         nan       \n",
      "NIH_C_3                       NIH                           x         nan       \n",
      "PSS_C_2                       PSS                           x         nan       \n",
      "PSS_C_4                       PSS                           x         nan       \n",
      "SPS_C_4                       SPS                           x         nan       \n",
      "VSA_C_1                       VSA                           x         nan       \n",
      "VSA_C_4                       VSA                           x         nan       \n",
      "Task_C_BIAT_99                BIAT                          x         \n",
      "Task_C_IAT_99                 IAT                           x         \n",
      "Task_C_AMP_99                 AMP                           x         \n",
      "Task_C_TR1_99                 TR1                           x         \n",
      "Task_C_ATT_99                 ATT                           x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "own_prev_choice\n",
      "p2_prev_choice\n",
      "p3_prev_choice\n",
      "p4_prev_choice\n",
      "own_outcome\n",
      "p2_outcome\n",
      "p3_outcome\n",
      "p4_outcome\n",
      "choice\n",
      "RT\n",
      "prev_wave\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "E\n",
      "['14', 'F', '8', '3', '15', 'K', '5', 'I', 'L', '13', 'M', '15b', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n",
      "['N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-243-c717968264a5>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 13. Lynn: NDAR Data Submission for Conte\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Lynn_Paul_NDAR_Data_Submission_for_Conte\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Lynn_Paul_NDAR_Data_Submission_for_Conte/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_4                  Unemployment_Stats            x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_4                  Unemployment_Stats            x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_4                  Unemployment_Stats            x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_4                  Unemployment_Stats            x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_4                  Unemployment_Stats            x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_4                  Unemployment_Stats            x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_4                  Unemployment_Stats            x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_10_4                 Unemployment_Stats            x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_4                 Unemployment_Stats            x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_4                 Unemployment_Stats            x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_4                 Unemployment_Stats            x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_4                 Unemployment_Stats            x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_4                 Unemployment_Stats            x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_4                 Unemployment_Stats            x         \n",
      "CVD_Data_17_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_17_4                 Unemployment_Stats            x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-244-d9222eee9645>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 14 Marie Christine: Self under stress\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Marie_Christine_The_Self_under_Stress\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Marie_Christine_The_Self_under_Stress/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "CVD_Data_1_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_1_4                  Unemployment_Stats            x         \n",
      "CVD_Data_2_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_2_4                  Unemployment_Stats            x         \n",
      "CVD_Data_3_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_3_4                  Unemployment_Stats            x         \n",
      "CVD_Data_4_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_4_4                  Unemployment_Stats            x         \n",
      "CVD_Data_5_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_5_4                  Unemployment_Stats            x         \n",
      "CVD_Data_6_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_6_4                  Unemployment_Stats            x         \n",
      "CVD_Data_7_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_7_4                  Unemployment_Stats            x         \n",
      "CVD_Data_8_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_8_4                  Unemployment_Stats            x         \n",
      "CVD_Data_9_3                  CVD_Data_Protest              x         \n",
      "CVD_Data_9_4                  Unemployment_Stats            x         \n",
      "CVD_Data_10_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_10_4                 Unemployment_Stats            x         \n",
      "CVD_Data_11_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_11_4                 Unemployment_Stats            x         \n",
      "CVD_Data_12_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_12_4                 Unemployment_Stats            x         \n",
      "CVD_Data_13_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_13_4                 Unemployment_Stats            x         \n",
      "CVD_Data_14_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_14_4                 Unemployment_Stats            x         \n",
      "CVD_Data_15_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_15_4                 Unemployment_Stats            x         \n",
      "CVD_Data_16_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_16_4                 Unemployment_Stats            x         \n",
      "CVD_Data_17_3                 CVD_Data_Protest              x         \n",
      "CVD_Data_17_4                 Unemployment_Stats            x         \n",
      "DSR_C_1                       nan                           x         \n",
      "\n",
      "These columns were not found in the data:\n",
      "state\n",
      "cumulative_cases\n",
      "new_cases\n",
      "slope_new_cases\n",
      "cumulative_deaths\n",
      "new_deaths\n",
      "slope_new_deaths\n",
      "Mandatory_SAH\n",
      "Recomm_SAH\n",
      "Mandatory_gather_limit\n",
      "Mandatory_gather_max\n",
      "Recomm_gather_limit\n",
      "Recomm_gather_max\n",
      "GatheringStrictness\n",
      "State_park_closure\n",
      "Playground_closure\n",
      "Mandatory_PPE_masks\n",
      "Recomm_PPE_masks\n",
      "Mandatory_business_closure\n",
      "Recomm_business_closure\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-245-b4b007cf7949>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 15 Tessa: Self Covid Core\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Tessa_Covid_Core\\request.csv'\n",
    "request_col = 3\n",
    "save_filename = './output/approved_projects/Tessa_Covid_Core/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNV                           request_label                 x         \n",
      "========================================================\n",
      "DSR_C_1                       nan                           x         \n",
      "NIH_C_1                       NIH                           x         nan       \n",
      "NIH_C_3                       NIH                           x         nan       \n",
      "PSS_C_2                       PSS                           x         nan       \n",
      "PSS_C_4                       PSS                           x         nan       \n",
      "\n",
      "These columns were not found in the data:\n",
      "mismatch_dem_age\n",
      "['14', 'F', '8', '3', 'N', '15', 'K', '5', 'I', 'L', '13', 'M', 'J', '15b', 'E', 'C', '4', 'B', '7', 'G', 'A', '1', '9', '10', '16', 'D', '17', '11', '6', '12', '2', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-246-3bd608a649e1>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  export(request, save_filename, data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mismatch_dem_age\n"
     ]
    }
   ],
   "source": [
    "# 15 Andy: Causal Effect of Lockdown\n",
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Andy_Causal_Effect_of_Lockdown\\request.csv'\n",
    "request_col = 2\n",
    "save_filename = './output/approved_projects/Andy_Causal_Effect_of_Lockdown/data.csv'\n",
    "request = process_request(request_filename, request_col, save_filename)\n",
    "export(request, save_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Invest_2</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>Uncovering Heterogeneity within Conspiracy The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Invest_3</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>Andy Liang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Invest_4</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>Chapman University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Invest_5</td>\n",
       "      <td>Prior to submitting a data-request, the COVID-...</td>\n",
       "      <td>liang134@mail.chapman.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Other_Investigators#1_1_1</td>\n",
       "      <td>All data will be distributed via Box to the PI...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>GFPS36v2_2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>GFPS37v2_1</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>GFPS37v2_2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>GFPS38v2_1</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>GFPS38v2_2</td>\n",
       "      <td>Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1549 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  \\\n",
       "17                     Invest_2   \n",
       "18                     Invest_3   \n",
       "19                     Invest_4   \n",
       "20                     Invest_5   \n",
       "21    Other_Investigators#1_1_1   \n",
       "...                         ...   \n",
       "1561                 GFPS36v2_2   \n",
       "1562                 GFPS37v2_1   \n",
       "1563                 GFPS37v2_2   \n",
       "1564                 GFPS38v2_1   \n",
       "1565                 GFPS38v2_2   \n",
       "\n",
       "                                                      0  \\\n",
       "17    Prior to submitting a data-request, the COVID-...   \n",
       "18    Prior to submitting a data-request, the COVID-...   \n",
       "19    Prior to submitting a data-request, the COVID-...   \n",
       "20    Prior to submitting a data-request, the COVID-...   \n",
       "21    All data will be distributed via Box to the PI...   \n",
       "...                                                 ...   \n",
       "1561  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1562  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1563  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1564  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "1565  Protest Survey 2 - Wave 8 - June 27, 2020 (Sel...   \n",
       "\n",
       "                                                      1  \n",
       "17    Uncovering Heterogeneity within Conspiracy The...  \n",
       "18                                           Andy Liang  \n",
       "19                                   Chapman University  \n",
       "20                            liang134@mail.chapman.edu  \n",
       "21                                                  NaN  \n",
       "...                                                 ...  \n",
       "1561                                                NaN  \n",
       "1562                                                NaN  \n",
       "1563                                                NaN  \n",
       "1564                                                NaN  \n",
       "1565                                                NaN  \n",
       "\n",
       "[1549 rows x 3 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_filename = r'C:\\Users\\andyl\\Box\\COVID-19 Adolphs Lab\\approved_projects\\Andy_Liang_Uncovering_Heterogeneity_within_Conspiracy_Theorists\\request.csv'\n",
    "request_col = 2\n",
    "request = inspect_request(request_filename)\n",
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>MHC_P_17</td>\n",
       "      <td>Mental Health Checkpoint - Prolific - Wave 17-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                                  0    1\n",
       "500  MHC_P_17  Mental Health Checkpoint - Prolific - Wave 17-...  NaN"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.loc[request['index'] == 'MHC_P_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_filename = '/Users/Work/Box/COVID-19 Adolphs Lab/approved_projects/Andy_Liang_Uncovering_Heterogeneity_within_Conspiracy_Theorists/request.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
